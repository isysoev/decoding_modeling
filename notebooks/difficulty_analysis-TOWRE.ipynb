{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "CQaLvAaO7bnB"
   },
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.distributions import * \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as scistats\n",
    "from scipy.special import binom\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from functools import reduce\n",
    "import seaborn as sb\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DZAvrsri8i4G"
   },
   "outputs": [],
   "source": [
    "DATA_PATH = '../data'\n",
    "import os\n",
    "import h5py\n",
    "from os.path import join, exists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bYOtwHPi_DqZ"
   },
   "source": [
    "#Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "L2l1CYLH7bnC"
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import codecs\n",
    "\n",
    "def get_basic_phoneme(phoneme):\n",
    "\tif phoneme[-1].isdigit():\n",
    "\t\treturn phoneme[:-1]\n",
    "\treturn phoneme\n",
    "\n",
    "def get_phonemes(phonemes_code):\n",
    "\treturn tuple([get_basic_phoneme(phoneme_code) for phoneme_code in phonemes_code.split(';')])\n",
    "\n",
    "def get_pg_pair(pg_pair_code):\n",
    "\tphonemes_code, grapheme = pg_pair_code.split('>')\n",
    "\treturn (get_phonemes(phonemes_code), grapheme)\n",
    "\n",
    "def get_mapping(mapping_code):\n",
    "\treturn tuple([get_pg_pair(pg_pair_code) for pg_pair_code in mapping_code.split('|')])\n",
    "\n",
    "def read_phonix(input_file_name):\n",
    "\tphonix = []\n",
    "\twith codecs.open(input_file_name, encoding = 'utf-8') as input_file:\n",
    "\t\tfor line in input_file:\n",
    "\t\t\tline = line.strip()\n",
    "\t\t\tif not line: continue\n",
    "\t\t\tword, mapping_code = line.split(' ')\n",
    "\t\t\tphonix.append((word, get_mapping(mapping_code)))\n",
    "\treturn phonix\n",
    "\n",
    "def pg_pair_to_str(pg_pair):\n",
    "\tphonemes, grapheme = pg_pair\n",
    "\treturn '%s>%s' % (';'.join(phonemes), grapheme)\n",
    "\n",
    "def mapping_to_str(mapping):\n",
    "\treturn '|'.join(pg_pair_to_str(pg_pair) for pg_pair in mapping)\n",
    " \n",
    "def read_freq_list(freq_file_name):\n",
    "    wordfreqs = {}\n",
    "    with open(freq_file_name) as input_file:\n",
    "        for line in input_file:\n",
    "            line = line.strip()\n",
    "            word, freq = line.split(' ')\n",
    "            freq = float(freq)\n",
    "            wordfreqs[word] = freq\n",
    "    return wordfreqs\n",
    "\n",
    "def get_pg_freqs(wordfreqs, phonix):\n",
    "    aggregator = defaultdict(float)\n",
    "    for word, mapping in phonix:\n",
    "        if word not in wordfreqs: continue\n",
    "        wordfreq = wordfreqs[word]\n",
    "        for pg in mapping:\n",
    "            aggregator[pg_pair_to_str(pg)] += wordfreq\n",
    "    return normalize(aggregator)\n",
    "\n",
    "def word_pgs(phonix_dict, word):\n",
    "    return [pg_pair_to_str(pg) for pg in phonix_dict[word]]\n",
    "    \n",
    "def observed_pgs(phonix_dict, observations):\n",
    "    pgs = set()\n",
    "    for word, obs in observations:\n",
    "        pgs.update(word_pgs(phonix_dict, word))\n",
    "    return pgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "cLQ2BAPM7bnC"
   },
   "outputs": [],
   "source": [
    "def normalize(distr):\n",
    "    denominator = sum(distr.values())\n",
    "    return {key: float(value) / denominator for key, value in distr.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "tTZGgcd_7bnC"
   },
   "outputs": [],
   "source": [
    "phonix = read_phonix(join(DATA_PATH, 'phonix.txt'))\n",
    "phonix_dict = dict(phonix)\n",
    "wordfreqs = read_freq_list(join(DATA_PATH, 'word-freqs.txt'))\n",
    "\n",
    "word_list = sorted(list(set(phonix_dict.keys()) & set(wordfreqs.keys() - {'null', 'nan'}))) \n",
    "#Above is because of strange behaviors with DF.\n",
    "\n",
    "pg_freqs = get_pg_freqs(wordfreqs, phonix)\n",
    "\n",
    "pgs = sorted(pg_freqs.keys(), key = lambda pg: pg_freqs[pg], reverse=True)\n",
    "ps = np.array([pg_freqs[pg] for pg in pgs])\n",
    "\n",
    "pg_idx = {pg : i for i, pg in enumerate(pgs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "towre_phonix = read_phonix(join(DATA_PATH, 'towre_phonix.txt'))\n",
    "towre_phonix_dict = dict(towre_phonix)\n",
    "targets = [w for w, m in towre_phonix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "1lFWjVQaVBUQ"
   },
   "outputs": [],
   "source": [
    "def gen_word2pg_counts(phonix_dict, word_list, pg_idx):\n",
    "  #Some code taken from Ivan's.\n",
    "\n",
    "  counts = []\n",
    "  for word in word_list:\n",
    "\n",
    "    #Identify idx of the pg pairs in word.\n",
    "    the_word_pgs = word_pgs(phonix_dict, word)\n",
    "    the_word_pgs_idx = np.array([pg_idx[pg] for pg in the_word_pgs])\n",
    "\n",
    "    #Convert to one-hot like vector of counts\n",
    "    this_counts = np.bincount(the_word_pgs_idx, minlength = len(pg_idx))\n",
    "    counts.append(this_counts)\n",
    "\n",
    "  return np.stack(counts)\n",
    "\n",
    "word2pg_counts = torch.from_numpy(gen_word2pg_counts(towre_phonix_dict, targets, pg_idx)) #.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ky89WdfO_H5c"
   },
   "source": [
    "#Difficulty computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "URecs1MOk9gH"
   },
   "outputs": [],
   "source": [
    "#12/7: https://www.tensorflow.org/probability\n",
    "#import tensorflow as tf\n",
    "#import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "1Q5-m8BZ7bnD"
   },
   "outputs": [],
   "source": [
    "def _probs_to_word_prob(probs_recall, word2pg_counts_arr):\n",
    "\n",
    "    #Note that if the count for a given pg is zero, the result is 1,\n",
    "    #  which doesn't affect the product as expected.\n",
    "    raw_products = torch.pow(probs_recall, word2pg_counts_arr) #Check idx ordering?\n",
    "    p_pg = torch.prod(raw_products, axis = 1) #Collapse pg, retain words.\n",
    "  \n",
    "    return p_pg\n",
    "    \n",
    "def simulate_child(word_list, prior_mu = np.log(500), prior_sigma = 3):\n",
    "\n",
    "    lr = 0.3\n",
    "\n",
    "    #12/7: https://stackoverflow.com/questions/34097281/convert-a-tensor-to-numpy-array-in-tensorflow\n",
    "    log_n = torch.normal(mean = torch.tensor([float(prior_mu)]), std = torch.tensor([float(prior_sigma)]))\n",
    "    n = int(np.ceil(np.exp(log_n.numpy())))\n",
    "\n",
    "    n_pg_raw = torch.multinomial(torch.from_numpy(ps), n, replacement=True) #Fictional counts only.\n",
    "    n_pg = torch.bincount(n_pg_raw, minlength = ps.shape[0])\n",
    "    \n",
    "    assert torch.sum(n_pg) == n, 'Allocation not correct.'\n",
    "    \n",
    "    #Simulate recalls.\n",
    "    probs_recall = 1 - torch.exp(-lr * n_pg)\n",
    "    words_probs = _probs_to_word_prob(probs_recall, word2pg_counts_arr = word2pg_counts)\n",
    "    recalled = torch.bernoulli(words_probs)\n",
    "    return recalled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def account_for_word_variants(word_list):\n",
    "    counter = defaultdict(int)\n",
    "    for word in word_list:\n",
    "        if '(' in word: word = word[:word.find('(')]\n",
    "        counter[word] += 1\n",
    "    agg_word_list = list(sorted(counter.keys()))\n",
    "    total_count = 0\n",
    "    agg_intervals = []\n",
    "    for word in mod_word_list:\n",
    "        cnt = counter[word]\n",
    "        agg_intervals.append((total_count, total_count + cnt))\n",
    "        total_count += cnt\n",
    "    return (agg_word_list, agg_intervals)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_word_list, agg_intervals = account_for_word_variants(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def account_for_variants(recall, agg_intervals):\n",
    "    agg = torch.zeros(len(agg_intervals), dtype = bool)\n",
    "    for i, (start, end) in enumerate(agg_intervals):\n",
    "        agg[i] = torch.any(recall[start : end].bool())\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "cMQjQIkeA4n-"
   },
   "outputs": [],
   "source": [
    "def repeat_simulation(word_list, agg_intervals, trials):\n",
    "\n",
    "  aggregate = torch.zeros((len(agg_intervals),))\n",
    "\n",
    "  for trial_num in range(trials):\n",
    "    if trial_num % 100 == 0:\n",
    "      print(f'Trial: {trial_num}')\n",
    "    this_child_recall = simulate_child(word_list)\n",
    "    aggregated_recall = account_for_variants(this_child_recall, agg_intervals)\n",
    "    aggregate += aggregated_recall\n",
    "\n",
    "  difficulty = 1 - (aggregate / trials)\n",
    "  return difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 0\n",
      "Trial: 100\n",
      "Trial: 200\n",
      "Trial: 300\n",
      "Trial: 400\n",
      "Trial: 500\n",
      "Trial: 600\n",
      "Trial: 700\n",
      "Trial: 800\n",
      "Trial: 900\n",
      "Trial: 1000\n",
      "Trial: 1100\n",
      "Trial: 1200\n",
      "Trial: 1300\n",
      "Trial: 1400\n",
      "Trial: 1500\n",
      "Trial: 1600\n",
      "Trial: 1700\n",
      "Trial: 1800\n",
      "Trial: 1900\n",
      "Trial: 2000\n",
      "Trial: 2100\n",
      "Trial: 2200\n",
      "Trial: 2300\n",
      "Trial: 2400\n",
      "Trial: 2500\n",
      "Trial: 2600\n",
      "Trial: 2700\n",
      "Trial: 2800\n",
      "Trial: 2900\n",
      "Trial: 3000\n",
      "Trial: 3100\n",
      "Trial: 3200\n",
      "Trial: 3300\n",
      "Trial: 3400\n",
      "Trial: 3500\n",
      "Trial: 3600\n",
      "Trial: 3700\n",
      "Trial: 3800\n",
      "Trial: 3900\n",
      "Trial: 4000\n",
      "Trial: 4100\n",
      "Trial: 4200\n",
      "Trial: 4300\n",
      "Trial: 4400\n",
      "Trial: 4500\n",
      "Trial: 4600\n",
      "Trial: 4700\n",
      "Trial: 4800\n",
      "Trial: 4900\n"
     ]
    }
   ],
   "source": [
    "difficulty = repeat_simulation(targets, agg_intervals, 5000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_difficulty = {agg_word_list[i] : float(difficulty[i]) for i in range(len(agg_word_list))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_difficulty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(join(DATA_PATH, \"towre-difficulty-estimate.csv\"), \"w\") as outfile:\n",
    "    print(\"word, difficulty\", file = outfile)\n",
    "    for word in sorted(word_difficulty.keys()):\n",
    "        print(\"%s,%f\" % (word, word_difficulty[word]), file = outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFormWords(form):\n",
    "    words = []\n",
    "    with open(join(DATA_PATH, \"TOWRE\", \"Form_%s.csv\" % form)) as infile:\n",
    "        for line in infile:\n",
    "            wrd = line[:line.find(\",\")]\n",
    "            if wrd in word_difficulty:\n",
    "                words.append(wrd)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ip',\n",
       " 'ga',\n",
       " 'ko',\n",
       " 'ta',\n",
       " 'om',\n",
       " 'ig',\n",
       " 'ni',\n",
       " 'pim',\n",
       " 'wum',\n",
       " 'lat',\n",
       " 'baf',\n",
       " 'din',\n",
       " 'nup',\n",
       " 'fet',\n",
       " 'bave',\n",
       " 'pate',\n",
       " 'herm',\n",
       " 'dess',\n",
       " 'chur',\n",
       " 'knap',\n",
       " 'tive',\n",
       " 'barp',\n",
       " 'stip',\n",
       " 'plin',\n",
       " 'frip',\n",
       " 'poth',\n",
       " 'vasp',\n",
       " 'meest',\n",
       " 'shlee',\n",
       " 'guddy',\n",
       " 'skree',\n",
       " 'felly',\n",
       " 'clirt',\n",
       " 'sline',\n",
       " 'dreef',\n",
       " 'prain',\n",
       " 'zint',\n",
       " 'bloot',\n",
       " 'trisk',\n",
       " 'kelm',\n",
       " 'strone',\n",
       " 'lunaf',\n",
       " 'cratty',\n",
       " 'trober',\n",
       " 'depate',\n",
       " 'glant',\n",
       " 'sploosh',\n",
       " 'dreker',\n",
       " 'ritlun',\n",
       " 'hedfert',\n",
       " 'bremick',\n",
       " 'nifpate',\n",
       " 'brinbert',\n",
       " 'clabom',\n",
       " 'drepnort',\n",
       " 'shrattec',\n",
       " 'plofent',\n",
       " 'smucrit',\n",
       " 'pelnador',\n",
       " 'fornalask',\n",
       " 'fermabalt',\n",
       " 'crenidmoke',\n",
       " 'emulbatate',\n",
       " 'strotalanted',\n",
       " 'prilingdorfent',\n",
       " 'chunfendilt']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getFormWords(\"A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, form in enumerate([\"A\", \"B\", \"C\", \"D\"]):\n",
    "    form_words = getFormWords(form)\n",
    "    plt.figure(i)\n",
    "    plt.scatter(range(len(form_words)), [word_difficulty[word] for word in form_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SNXr1glZahgl"
   },
   "source": [
    "#Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "_XXQZn5FXbfV"
   },
   "outputs": [],
   "source": [
    "def test_gen_word2pg_counts():\n",
    "  test_word_list = ['can', 'cactus']\n",
    "\n",
    "  #Manually from pg_idx and phonix_dict:\n",
    "  #'ʌ>a' -> 15\n",
    "  #'k>c' -> 22\n",
    "  #'n>n' -> 1\n",
    "  #'æ>a' -> 4\n",
    "  #'t>t' -> 0\n",
    "  #'ʌ>u' -> 21\n",
    "  #'s>s' -> 5\n",
    "\n",
    "  actual = gen_word2pg_counts(test_word_list, pg_idx)\n",
    "  list_where_one = [[22, 15, 1], [22, 4, 0, 21, 5]]\n",
    "\n",
    "  expected = []\n",
    "  for where_one in list_where_one:\n",
    "    this_expected = np.zeros(len(pg_idx))\n",
    "    this_expected[where_one] = 1\n",
    "    expected.append(this_expected)\n",
    "\n",
    "  expected[1][22] = 2 #Two k>c in \"cactus\".\n",
    "  expected = np.stack(expected)\n",
    "\n",
    "  assert np.all(actual == expected), 'word2pgcounts function check failed.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "UcLLGx0uedXJ"
   },
   "outputs": [],
   "source": [
    "def test_probs_to_word_prob():\n",
    "  test_recall_probs = torch.from_numpy(np.array([2., 1., 3.]))\n",
    "  test_counts = torch.from_numpy(np.array([\n",
    "                          [0, 3, 2],\n",
    "                          [1, 1, 0],\n",
    "                          [3, 1, 2]\n",
    "  ]))\n",
    "\n",
    "  expected = torch.Tensor([9, 2, 72])\n",
    "  actual = _probs_to_word_prob(test_recall_probs, test_counts)\n",
    "\n",
    "  assert torch.all(expected == actual), 'probs to word prob test failed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RswttDWPedvf",
    "outputId": "8f0964eb-ef01-4eee-c951-34d65268dc74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests passed.\n"
     ]
    }
   ],
   "source": [
    "tests = [\n",
    "         test_gen_word2pg_counts,\n",
    "         test_probs_to_word_prob\n",
    "]\n",
    "\n",
    "for test in tests:\n",
    "  test()\n",
    "\n",
    "print('Tests passed.')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "SNXr1glZahgl"
   ],
   "name": "difficulty analysis.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
